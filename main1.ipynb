{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c0aadb",
   "metadata": {},
   "source": [
    "# MIT xPro Deep Learning Capstone\n",
    "### Anthony Rowlands\n",
    "### 7/18/2025\n",
    "\n",
    "This project trains a simple chess engine neural network. It attempts to find the next best move on a chess board, given an initial board state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884db36a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b6d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!mkdir -p data\n",
    "!gdown --id 1-xuXCF0hYq7dBGtuJmVtryCzx9awE29H -O ./data/fics-2024.pgn\n",
    "!gdown --id 1uG0Cr1MLr5Ds9yK8tN-R3lp6r8t0ZGaB -O ./data/moves_legal_uci.txt\n",
    "!pip install chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import chess\n",
    "import chess.pgn\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "MOVES_FILE = DATA_DIR.joinpath('moves_legal_uci.txt')\n",
    "\n",
    "with open(MOVES_FILE, 'r', encoding='utf-8') as f:\n",
    "    ALL_MOVES = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "MOVE_TO_INDEX = {m: i for i, m in enumerate(ALL_MOVES)}\n",
    "INDEX_TO_MOVE = ALL_MOVES\n",
    "\n",
    "def encode_board(board: 'chess.Board') -> torch.Tensor:\n",
    "    planes = np.zeros((18, 8, 8), dtype=np.float32)\n",
    "    piece_type_to_index = {\n",
    "        chess.PAWN: 0,\n",
    "        chess.KNIGHT: 1,\n",
    "        chess.BISHOP: 2,\n",
    "        chess.ROOK: 3,\n",
    "        chess.QUEEN: 4,\n",
    "        chess.KING: 5\n",
    "    }\n",
    "    for square, piece in board.piece_map().items():\n",
    "        rank = chess.square_rank(square)\n",
    "        file = chess.square_file(square)\n",
    "        base = piece_type_to_index[piece.piece_type]\n",
    "        channel = base if piece.color == chess.WHITE else base + 6\n",
    "        planes[channel, 7 - rank, file] = 1.0\n",
    "    if board.turn == chess.WHITE:\n",
    "        planes[12, :, :] = 1.0\n",
    "    if board.has_kingside_castling_rights(chess.WHITE):\n",
    "        planes[13, :, :] = 1.0\n",
    "    if board.has_queenside_castling_rights(chess.WHITE):\n",
    "        planes[14, :, :] = 1.0\n",
    "    if board.has_kingside_castling_rights(chess.BLACK):\n",
    "        planes[15, :, :] = 1.0\n",
    "    if board.has_queenside_castling_rights(chess.BLACK):\n",
    "        planes[16, :, :] = 1.0\n",
    "    if board.ep_square is not None:\n",
    "        r = chess.square_rank(board.ep_square)\n",
    "        f = chess.square_file(board.ep_square)\n",
    "        planes[17, 7 - r, f] = 1.0\n",
    "    return torch.from_numpy(planes)\n",
    "\n",
    "class ChessNextMoveDataset(Dataset):\n",
    "    def __init__(self, games, move_to_index):\n",
    "        self.games = games\n",
    "        self.move_to_index = move_to_index\n",
    "        self.game_moves = [list(g.mainline_moves()) for g in games]\n",
    "        self.sample_index = []\n",
    "        for gi, moves in enumerate(self.game_moves):\n",
    "            for ply_idx, move in enumerate(moves):\n",
    "                uci = move.uci()\n",
    "                if uci in self.move_to_index:\n",
    "                    self.sample_index.append((gi, ply_idx))\n",
    "    def __len__(self):\n",
    "        return len(self.sample_index)\n",
    "    def __getitem__(self, idx):\n",
    "        gi, ply_idx = self.sample_index[idx]\n",
    "        moves = self.game_moves[gi]\n",
    "        board = chess.Board()\n",
    "        for m in moves[:ply_idx]:\n",
    "            board.push(m)\n",
    "        x = encode_board(board)\n",
    "        y = self.move_to_index[moves[ply_idx].uci()]\n",
    "        return x, y\n",
    "\n",
    "def collate_batch(batch):\n",
    "    xs = torch.stack([b[0] for b in batch], dim=0)\n",
    "    ys = torch.tensor([b[1] for b in batch], dtype=torch.long)\n",
    "    return xs, ys\n",
    "\n",
    "class NextMoveCNN(nn.Module):\n",
    "    def __init__(self, num_moves: int):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(18, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 2 * 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_moves)\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def top1_accuracy(logits: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct = (preds == targets).sum().item()\n",
    "    total = targets.size(0)\n",
    "    return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957124f3",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "PGN_FILE = DATA_DIR.joinpath('fics-2024.pgn')\n",
    "with open(PGN_FILE, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    pgn_lines = f.read().splitlines()\n",
    "\n",
    "def parse_games_from_pgn_lines(lines: List[str]) -> List['chess.pgn.Game']:\n",
    "    games = []\n",
    "    for line in lines:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        game_io = io.StringIO(line.strip())\n",
    "        try:\n",
    "            game = chess.pgn.read_game(game_io)\n",
    "            if game is not None and game.mainline_moves() is not None:\n",
    "                games.append(game)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return games\n",
    "\n",
    "def train_val_test_split(games):\n",
    "    n = len(games)\n",
    "    a = int(n * 0.7)\n",
    "    b = int(n * 0.85)\n",
    "    return games[:a], games[a:b], games[b:]\n",
    "\n",
    "def build_loaders(train_games, val_games, test_games, batch_size=256, num_workers=0):\n",
    "    train_ds = ChessNextMoveDataset(train_games, MOVE_TO_INDEX)\n",
    "    val_ds = ChessNextMoveDataset(val_games, MOVE_TO_INDEX)\n",
    "    test_ds = ChessNextMoveDataset(test_games, MOVE_TO_INDEX)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_batch)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=collate_batch)\n",
    "    return {'train': train_loader, 'val': val_loader, 'test': test_loader}, {'train': len(train_ds), 'val': len(val_ds), 'test': len(test_ds)}\n",
    "\n",
    "best_epoch = 0\n",
    "training_curves = {}\n",
    "\n",
    "def train():\n",
    "    global model, training_curves, best_epoch, dataloaders, dataset_sizes\n",
    "    games = parse_games_from_pgn_lines(pgn_lines)\n",
    "    train_games, val_games, test_games = train_val_test_split(games)\n",
    "    dataloaders, dataset_sizes = build_loaders(train_games, val_games, test_games)\n",
    "    model = NextMoveCNN(num_moves=len(INDEX_TO_MOVE)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "    phases = ['train', 'val', 'test']\n",
    "    training_curves = {}\n",
    "    for p in phases:\n",
    "        training_curves[p + '_loss'] = []\n",
    "        training_curves[p + '_acc'] = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "    best_epoch_local = 0\n",
    "    num_epochs = 5\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            count = 0\n",
    "            for xb, yb in dataloaders[phase]:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    logits = model(xb)\n",
    "                    loss = criterion(logits, yb)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                running_loss += loss.item() * xb.size(0)\n",
    "                running_corrects += (preds == yb).sum().item()\n",
    "                count += xb.size(0)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            epoch_loss = running_loss / count if count > 0 else 0.0\n",
    "            epoch_acc = running_corrects / count if count > 0 else 0.0\n",
    "            training_curves[phase + '_loss'].append(epoch_loss)\n",
    "            training_curves[phase + '_acc'].append(epoch_acc)\n",
    "            if phase == 'val' and epoch_acc > best_val_acc:\n",
    "                best_val_acc = epoch_acc\n",
    "                best_epoch_local = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    best_epoch = best_epoch_local\n",
    "\n",
    "def load():\n",
    "    global model, training_curves, best_epoch, dataloaders, dataset_sizes\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    except Exception:\n",
    "        pass\n",
    "    if not LOAD_MODEL_NAME:\n",
    "        raise ValueError('Set LOAD_MODEL_NAME to load an existing model')\n",
    "    games = parse_games_from_pgn_lines(pgn_lines)\n",
    "    train_games, val_games, test_games = train_val_test_split(games)\n",
    "    dataloaders, dataset_sizes = build_loaders(train_games, val_games, test_games)\n",
    "    checkpoint = torch.load(f'{models_dir}/{LOAD_MODEL_NAME}', map_location=device)\n",
    "    model = NextMoveCNN(num_moves=len(INDEX_TO_MOVE)).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    training_curves = {'train_loss': [], 'val_loss': [], 'test_loss': [], 'train_acc': [], 'val_acc': [], 'test_acc': []}\n",
    "    if LOAD_CURVES_NAME:\n",
    "        try:\n",
    "            with open(f'{models_dir}/{LOAD_CURVES_NAME}') as f:\n",
    "                training_curves = json.load(f)\n",
    "        except Exception:\n",
    "            pass\n",
    "    best_epoch = int(checkpoint.get('best_epoch', 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9fc18d",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fdfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_curves['train_loss'], label='train')\n",
    "plt.plot(training_curves['val_loss'], label='val')\n",
    "plt.plot(training_curves['test_loss'], label='test')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_curves['train_acc'], label='train')\n",
    "plt.plot(training_curves['val_acc'], label='val')\n",
    "plt.plot(training_curves['test_acc'], label='test')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_trues = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in dataloaders['test']:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_trues.extend(yb.numpy().tolist())\n",
    "\n",
    "if len(all_trues) > 0:\n",
    "    from matplotlib.colors import LogNorm\n",
    "    labels = list(range(len(INDEX_TO_MOVE)))\n",
    "    cm = confusion_matrix(all_trues, all_preds, labels=labels)\n",
    "    print({'cm_shape': cm.shape, 'total': int(cm.sum()), 'nonzero': int((cm > 0).sum())})\n",
    "    cm_plot = cm.astype(float)\n",
    "    cm_plot[cm_plot == 0] = np.nan\n",
    "    plt.figure(figsize=(20, 20), dpi=100)\n",
    "    im = plt.imshow(cm_plot, aspect='auto', interpolation='nearest', cmap='RdYlGn', norm=LogNorm(vmin=1, vmax=np.nanmax(cm_plot)))\n",
    "    plt.title('Confusion matrix (all moves)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.colorbar(im)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744003e4",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f0041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_move_from_pgn(pgn_moves_text: str) -> str:\n",
    "    game_io = io.StringIO(pgn_moves_text.strip())\n",
    "    game = chess.pgn.read_game(game_io)\n",
    "    if game is None:\n",
    "        return ''\n",
    "    board = chess.Board()\n",
    "    for m in game.mainline_moves():\n",
    "        board.push(m)\n",
    "    x = encode_board(board).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        idx = int(torch.argmax(probs, dim=1).item())\n",
    "        return INDEX_TO_MOVE[idx]\n",
    "\n",
    "manual_test_pgn = \"1. d4 d5 2. Nf3 Nf6 3. g3 Bf5 4. Bg2 e6 5. c4 c6 6. Nc3 h6 7. O-O Be7 8. Nd2 O-O 9. e4 dxe4 10. Ndxe4 Nbd7\"\n",
    "predict_next_move_from_pgn(manual_test_pgn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01e66b",
   "metadata": {},
   "source": [
    "## Save to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os, json, torch\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "models_dir = '/content/drive/MyDrive/MIT xPro Deep Learning/Capstone/models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "model_timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "model_path = f'{models_dir}/model-{model_timestamp}.pt'\n",
    "curves_path = f'{models_dir}/training_curves-{model_timestamp}.json'\n",
    "\n",
    "torch.save({'model_state_dict': model.state_dict(), 'num_moves': len(INDEX_TO_MOVE), 'best_epoch': best_epoch}, model_path)\n",
    "with open(curves_path, 'w') as f:\n",
    "  json.dump(training_curves, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb2508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_existing_model = True\n",
    "models_dir = '/content/drive/MyDrive/MIT xPro Deep Learning/Capstone/models'\n",
    "\n",
    "LOAD_MODEL_NAME = ''\n",
    "LOAD_CURVES_NAME = ''\n",
    "\n",
    "if load_existing_model:\n",
    "  load()\n",
    "else:\n",
    "  train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
